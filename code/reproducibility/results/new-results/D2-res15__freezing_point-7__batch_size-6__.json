{
    "setup": {
        "filename": "D2-res15__freezing_point-7__batch_size-6__.json",
        "dataset": "D2-res15",
        "device": "NVIDIA GeForce RTX 3050 Laptop GPU",
        "model_param": {
            "tag": "bert unfreeze layers",
            "freezing_point": 7,
            "prefix": "../data/D2/",
            "model_dir": "savemodel/",
            "task": "triplet",
            "mode": "train",
            "dataset": "res15",
            "max_sequence_len": 102,
            "device": "cuda",
            "bert_model_path": "bert-base-uncased",
            "bert_feature_dim": 768,
            "batch_size": 6,
            "epochs": 100,
            "class_num": 10,
            "seed": 1000,
            "learning_rate": 0.001,
            "bert_lr": 2e-05,
            "adam_epsilon": 1e-08,
            "weight_decay": 0.0,
            "emb_dropout": 0.5,
            "num_layers": 1,
            "pooling": "avg",
            "gcn_dim": 300,
            "relation_constraint": true,
            "symmetry_decoding": false,
            "post_size": 70,
            "deprel_size": 45,
            "postag_size": 826,
            "synpost_size": 7
        }
    },
    "results": {
        "dev_set": [
            0.34782608695652173,
            0.32132963988919666,
            0.3968,
            0.47953216374269003,
            0.5265588914549653,
            0.5995423340961098,
            0.6119096509240247,
            0.5924453280318092,
            0.532871972318339,
            0.5211062590975255,
            0.5682819383259912,
            0.5844594594594595,
            0.5276967930029155,
            0.5400313971742543,
            0.6127167630057803,
            0.5951557093425606,
            0.6169844020797227,
            0.6216216216216216,
            0.6476190476190475,
            0.6201550387596899,
            0.6200378071833649,
            0.6024096385542169,
            0.6317907444668007,
            0.609009009009009,
            0.6612244897959184,
            0.6036363636363636,
            0.6286764705882353,
            0.6024955436720143,
            0.6114180478821363,
            0.6233766233766234,
            0.6242774566473989,
            0.5866666666666668,
            0.5978260869565218,
            0.6457925636007829,
            0.6007604562737642,
            0.5742904841402338,
            0.5975395430579965,
            0.6263736263736265,
            0.6446601941747573,
            0.6137566137566138,
            0.5985915492957747,
            0.5907473309608542,
            0.6247689463955638,
            0.6290018832391714,
            0.6003430531732418,
            0.6118067978533095,
            0.6142595978062156,
            0.6383763837638377,
            0.6137184115523466,
            0.6351606805293004,
            0.6365348399246705,
            0.6040515653775322,
            0.6156583629893239,
            0.6436781609195402,
            0.6252285191956125,
            0.6487523992322457,
            0.6021897810218977,
            0.6504672897196262,
            0.6436781609195402,
            0.6213592233009709,
            0.6561264822134387,
            0.626865671641791,
            0.5888888888888889,
            0.6551724137931034,
            0.654690618762475,
            0.6306306306306305,
            0.6188811188811189,
            0.6252354048964218,
            0.6457564575645756,
            0.6247755834829445,
            0.6303236797274275,
            0.6284722222222222,
            0.6191304347826087,
            0.5964285714285713,
            0.6499102333931778,
            0.61139896373057,
            0.6353790613718412,
            0.6423357664233578,
            0.6470588235294118,
            0.6283662477558348,
            0.6415770609318996,
            0.6392857142857143,
            0.6216696269982237,
            0.6382978723404256,
            0.6365280289330923,
            0.6529080675422138,
            0.6779661016949153,
            0.6300884955752213,
            0.6499102333931778,
            0.6521739130434784,
            0.6091370558375634,
            0.6404293381037567,
            0.5855263157894737,
            0.6409807355516638,
            0.6236559139784946,
            0.6219081272084805,
            0.6176470588235294,
            0.6325411334552101,
            0.6252220248667851,
            0.611888111888112
        ],
        "best_epoch": 86,
        "best_epoch_f1": 0.6779661016949153,
        "training_time": 2353.477786540985,
        "test_set": {
            "f1": 0.5694164989939638,
            "precision": 0.555992141453831,
            "recall": 0.5835051546391753
        }
    }
}