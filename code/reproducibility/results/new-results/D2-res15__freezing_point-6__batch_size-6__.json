{
    "setup": {
        "filename": "D2-res15__freezing_point-6__batch_size-6__.json",
        "dataset": "D2-res15",
        "device": "NVIDIA GeForce RTX 3050 Laptop GPU",
        "model_param": {
            "tag": "bert unfreeze layers",
            "freezing_point": 6,
            "prefix": "../data/D2/",
            "model_dir": "savemodel/",
            "task": "triplet",
            "mode": "train",
            "dataset": "res15",
            "max_sequence_len": 102,
            "device": "cuda",
            "bert_model_path": "bert-base-uncased",
            "bert_feature_dim": 768,
            "batch_size": 6,
            "epochs": 100,
            "class_num": 10,
            "seed": 1000,
            "learning_rate": 0.001,
            "bert_lr": 2e-05,
            "adam_epsilon": 1e-08,
            "weight_decay": 0.0,
            "emb_dropout": 0.5,
            "num_layers": 1,
            "pooling": "avg",
            "gcn_dim": 300,
            "relation_constraint": true,
            "symmetry_decoding": false,
            "post_size": 70,
            "deprel_size": 45,
            "postag_size": 826,
            "synpost_size": 7
        }
    },
    "results": {
        "dev_set": [
            0.3531827515400411,
            0.32152588555858314,
            0.4244372990353698,
            0.5590062111801242,
            0.5558086560364464,
            0.6382022471910113,
            0.5920826161790017,
            0.6112185686653772,
            0.5673981191222571,
            0.5792,
            0.6222222222222221,
            0.6460980036297641,
            0.6300884955752213,
            0.5951557093425606,
            0.5982905982905983,
            0.6277372262773723,
            0.6290018832391714,
            0.6282527881040892,
            0.6335174953959485,
            0.6450304259634888,
            0.6187050359712231,
            0.625,
            0.6390977443609023,
            0.6153846153846153,
            0.651252408477842,
            0.6356589147286822,
            0.6216696269982237,
            0.6428571428571428,
            0.6275303643724697,
            0.63003663003663,
            0.6370370370370371,
            0.6346863468634686,
            0.6223021582733813,
            0.59402460456942,
            0.6176470588235294,
            0.6366906474820143,
            0.6309963099630995,
            0.6252220248667851,
            0.6306306306306305,
            0.6201022146507665,
            0.6452762923351159,
            0.6444444444444445,
            0.6541353383458647,
            0.6420664206642066,
            0.6375227686703097,
            0.6452830188679246,
            0.6397058823529412,
            0.6559139784946236,
            0.6444833625218913,
            0.6431095406360424,
            0.6615384615384615,
            0.6431226765799256,
            0.6431226765799256,
            0.6424682395644282,
            0.6468401486988847,
            0.6561264822134387,
            0.6375711574952562,
            0.638532110091743,
            0.6465028355387523,
            0.6564299424184261,
            0.6508226691042047,
            0.6615969581749049,
            0.6554934823091249,
            0.6603053435114504,
            0.6679462571976967,
            0.6327272727272727,
            0.65,
            0.6295585412667947,
            0.6513409961685824,
            0.6425855513307985,
            0.6573705179282869,
            0.6543438077634011,
            0.6487523992322457,
            0.6575875486381322,
            0.6416510318949343,
            0.6832061068702289,
            0.6679764243614932,
            0.6536203522504893,
            0.6374781085814359,
            0.632688927943761,
            0.6370967741935484,
            0.6099290780141844,
            0.6336996336996338,
            0.6073298429319373,
            0.6390977443609023,
            0.6363636363636364,
            0.6479400749063671,
            0.6449275362318841,
            0.64030131826742,
            0.6552380952380953,
            0.6383763837638377,
            0.6412213740458016,
            0.6271510516252389,
            0.6351606805293004,
            0.6615087040618955,
            0.6405959031657356,
            0.6493506493506493,
            0.6559356136820925,
            0.641732283464567,
            0.6309963099630995
        ],
        "best_epoch": 75,
        "best_epoch_f1": 0.6832061068702289,
        "training_time": 2402.942930698395,
        "test_set": {
            "f1": 0.592814371257485,
            "precision": 0.574468085106383,
            "recall": 0.6123711340206186
        }
    }
}