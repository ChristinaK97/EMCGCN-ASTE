{
    "setup": {
        "filename": "D2-res15__freezing_point-5__batch_size-6__.json",
        "dataset": "D2-res15",
        "device": "NVIDIA GeForce RTX 3050 Laptop GPU",
        "model_param": {
            "tag": "bert unfreeze layers",
            "freezing_point": 5,
            "prefix": "../data/D2/",
            "model_dir": "savemodel/",
            "task": "triplet",
            "mode": "train",
            "dataset": "res15",
            "max_sequence_len": 102,
            "device": "cuda",
            "bert_model_path": "bert-base-uncased",
            "bert_feature_dim": 768,
            "batch_size": 6,
            "epochs": 100,
            "class_num": 10,
            "seed": 1000,
            "learning_rate": 0.001,
            "bert_lr": 2e-05,
            "adam_epsilon": 1e-08,
            "weight_decay": 0.0,
            "emb_dropout": 0.5,
            "num_layers": 1,
            "pooling": "avg",
            "gcn_dim": 300,
            "relation_constraint": true,
            "symmetry_decoding": false,
            "post_size": 70,
            "deprel_size": 45,
            "postag_size": 826,
            "synpost_size": 7
        }
    },
    "results": {
        "dev_set": [
            0.3541247484909457,
            0.3249669749009247,
            0.44122383252818037,
            0.5870841487279843,
            0.5404040404040403,
            0.6490066225165563,
            0.5845648604269295,
            0.6190476190476191,
            0.565284178187404,
            0.6027397260273972,
            0.5972696245733788,
            0.6381461675579323,
            0.6584070796460176,
            0.6325088339222614,
            0.6360424028268551,
            0.6434108527131782,
            0.62803738317757,
            0.651685393258427,
            0.6469500924214417,
            0.6313799621928167,
            0.629695885509839,
            0.6143106457242583,
            0.6279491833030854,
            0.6553030303030303,
            0.651252408477842,
            0.6515151515151515,
            0.6227106227106228,
            0.660377358490566,
            0.6236559139784946,
            0.6502835538752363,
            0.6382189239332097,
            0.656934306569343,
            0.6478342749529191,
            0.6628352490421455,
            0.6641366223908918,
            0.6811023622047244,
            0.6691729323308271,
            0.6183074265975821,
            0.6960000000000001,
            0.6706114398422092,
            0.6847195357833655,
            0.6604477611940298,
            0.6499032882011605,
            0.5734939759036145,
            0.6325088339222614,
            0.6368932038834952,
            0.6373626373626373,
            0.6366906474820143,
            0.6268115942028984,
            0.6048951048951048,
            0.6143106457242583,
            0.6425855513307985,
            0.6716417910447762,
            0.6112115732368897,
            0.6489563567362429,
            0.6258992805755397,
            0.6731898238747553,
            0.658273381294964,
            0.6604127579737336,
            0.6366906474820143,
            0.6536964980544747,
            0.6666666666666667,
            0.6982248520710059,
            0.6654343807763402,
            0.6576923076923077,
            0.671785028790787,
            0.6718146718146719,
            0.6619217081850534,
            0.6568807339449542,
            0.67816091954023,
            0.6704119850187266,
            0.6629001883239172,
            0.6810176125244618,
            0.6779661016949153,
            0.679245283018868,
            0.6566604127579737,
            0.6666666666666666,
            0.6544789762340036,
            0.6564299424184261,
            0.6203208556149733,
            0.6589595375722543,
            0.6218181818181817,
            0.6654275092936803,
            0.6641929499072355,
            0.6936416184971098,
            0.6692913385826772,
            0.649155722326454,
            0.6404293381037567,
            0.6788990825688074,
            0.6556169429097606,
            0.6737967914438502,
            0.6692307692307693,
            0.6805293005671078,
            0.6641509433962264,
            0.6421052631578947,
            0.64376130198915,
            0.6785009861932939,
            0.6741154562383612,
            0.6703499079189688,
            0.6602316602316602
        ],
        "best_epoch": 62,
        "best_epoch_f1": 0.6982248520710059,
        "training_time": 2488.313350915909,
        "test_set": {
            "f1": 0.6045548654244307,
            "precision": 0.6070686070686071,
            "recall": 0.6020618556701031
        }
    }
}