{
    "setup": {
        "filename": "D2-res15__freezing_point-4__batch_size-6__.json",
        "dataset": "D2-res15",
        "device": "NVIDIA GeForce RTX 3050 Laptop GPU",
        "model_param": {
            "tag": "bert unfreeze layers",
            "freezing_point": 4,
            "prefix": "../data/D2/",
            "model_dir": "savemodel/",
            "task": "triplet",
            "mode": "train",
            "dataset": "res15",
            "max_sequence_len": 102,
            "device": "cuda",
            "bert_model_path": "bert-base-uncased",
            "bert_feature_dim": 768,
            "batch_size": 6,
            "epochs": 100,
            "class_num": 10,
            "seed": 1000,
            "learning_rate": 0.001,
            "bert_lr": 2e-05,
            "adam_epsilon": 1e-08,
            "weight_decay": 0.0,
            "emb_dropout": 0.5,
            "num_layers": 1,
            "pooling": "avg",
            "gcn_dim": 300,
            "relation_constraint": true,
            "symmetry_decoding": false,
            "post_size": 70,
            "deprel_size": 45,
            "postag_size": 826,
            "synpost_size": 7
        }
    },
    "results": {
        "dev_set": [
            0.36174636174636177,
            0.3307086614173228,
            0.44657097288676234,
            0.5714285714285714,
            0.546875,
            0.6191446028513239,
            0.5388127853881278,
            0.6168582375478927,
            0.5648148148148148,
            0.6200716845878135,
            0.6265938069216759,
            0.6441281138790036,
            0.6415770609318996,
            0.6366906474820143,
            0.6389413988657844,
            0.6903353057199211,
            0.6729678638941399,
            0.6505576208178437,
            0.6833976833976834,
            0.6424682395644282,
            0.64030131826742,
            0.6589595375722543,
            0.6617915904936015,
            0.6495412844036696,
            0.6411657559198543,
            0.6436363636363636,
            0.6422018348623854,
            0.6377358490566037,
            0.6405959031657356,
            0.6642066420664208,
            0.6589147286821706,
            0.629090909090909,
            0.6441351888667992,
            0.5941278065630399,
            0.6124567474048442,
            0.66793893129771,
            0.649155722326454,
            0.6340579710144927,
            0.6427221172022685,
            0.5901639344262295,
            0.6520947176684881,
            0.6553672316384181,
            0.649056603773585,
            0.64804469273743,
            0.6219081272084805,
            0.6439393939393939,
            0.6557377049180328,
            0.6431226765799256,
            0.6704545454545455,
            0.6653696498054474,
            0.6731898238747553,
            0.6475849731663685,
            0.6543438077634011,
            0.6539923954372624,
            0.6291739894551845,
            0.6716141001855289,
            0.647377938517179,
            0.6604477611940298,
            0.6666666666666666,
            0.6703703703703703,
            0.6628571428571429,
            0.6104129263913824,
            0.6363636363636364,
            0.6178010471204188,
            0.6050420168067226,
            0.6398537477148081,
            0.664246823956443,
            0.6254416961130741,
            0.6631393298059964,
            0.6560283687943262,
            0.6819047619047619,
            0.660482374768089,
            0.6915887850467289,
            0.6666666666666666,
            0.6839186691312384,
            0.6928838951310862,
            0.65,
            0.6716417910447762,
            0.6332737030411449,
            0.6859344894026975,
            0.6097560975609756,
            0.6764705882352942,
            0.6856060606060607,
            0.6571936056838367,
            0.6865671641791045,
            0.6791044776119404,
            0.6522522522522523,
            0.6431095406360424,
            0.6654343807763402,
            0.6788990825688074,
            0.6559139784946236,
            0.6594202898550725,
            0.673076923076923,
            0.6321626617375231,
            0.6592592592592593,
            0.6324786324786326,
            0.596875,
            0.6428571428571428,
            0.6785714285714286,
            0.6765799256505576
        ],
        "best_epoch": 75,
        "best_epoch_f1": 0.6928838951310862,
        "training_time": 2250.339692592621,
        "test_set": {
            "f1": 0.6334661354581672,
            "precision": 0.6127167630057804,
            "recall": 0.6556701030927835
        }
    }
}