{
    "setup": {
        "filename": "D2-lap14__batch_size-6__use_feat-post-deprel-.json",
        "dataset": "D2-lap14",
        "device": "NVIDIA GeForce RTX 3050 Laptop GPU",
        "model_param": {
            "tag": "Train with rel pos dist and dependency combo",
            "use_features": [
                "post",
                "deprel"
            ],
            "prefix": "../data/D2/",
            "model_dir": "savemodel/",
            "task": "triplet",
            "mode": "train",
            "dataset": "lap14",
            "max_sequence_len": 102,
            "device": "cuda",
            "bert_model_path": "bert-base-uncased",
            "bert_feature_dim": 768,
            "batch_size": 6,
            "epochs": 100,
            "class_num": 10,
            "seed": 1000,
            "learning_rate": 0.001,
            "bert_lr": 2e-05,
            "adam_epsilon": 1e-08,
            "weight_decay": 0.0,
            "emb_dropout": 0.5,
            "num_layers": 1,
            "pooling": "avg",
            "gcn_dim": 300,
            "relation_constraint": true,
            "symmetry_decoding": false,
            "post_size": 85,
            "deprel_size": 44
        }
    },
    "results": {
        "dev_set": [
            0.2402707275803722,
            0.35130970724191063,
            0.4412698412698413,
            0.4283765347885402,
            0.4890829694323144,
            0.4967532467532467,
            0.5024,
            0.5245398773006135,
            0.5085271317829457,
            0.49283667621776506,
            0.49933949801849403,
            0.5118219749652294,
            0.4728682170542636,
            0.5142857142857142,
            0.46535947712418296,
            0.5550660792951542,
            0.5146666666666666,
            0.5006353240152478,
            0.5285524568393094,
            0.5132075471698113,
            0.5348258706467661,
            0.5371900826446281,
            0.5429740791268757,
            0.5537555228276878,
            0.543956043956044,
            0.532235939643347,
            0.5405405405405406,
            0.5195530726256982,
            0.5340599455040872,
            0.543884892086331,
            0.5697674418604651,
            0.5680119581464872,
            0.5478260869565217,
            0.5479452054794519,
            0.5508474576271186,
            0.5408299866131191,
            0.5283018867924529,
            0.5569620253164557,
            0.4827586206896552,
            0.5373563218390806,
            0.5511811023622047,
            0.5546448087431693,
            0.5557163531114326,
            0.533515731874145,
            0.554016620498615,
            0.5588235294117646,
            0.5566714490674318,
            0.5545977011494253,
            0.559201141226819,
            0.5547445255474452,
            0.5647743813682679,
            0.5667655786350148,
            0.5590778097982709,
            0.5451851851851853,
            0.5593451568894953,
            0.5637393767705382,
            0.5426997245179063,
            0.5658682634730537,
            0.5206258890469417,
            0.5341426403641881,
            0.5494830132939439,
            0.528,
            0.5065274151436032,
            0.5181208053691275,
            0.5240054869684498,
            0.5606936416184971,
            0.5692068429237948,
            0.5477888730385164,
            0.5673758865248227,
            0.5568942436412316,
            0.5571030640668524,
            0.5277044854881267,
            0.5641748942172073,
            0.5513513513513514,
            0.548431105047749,
            0.5509325681492109,
            0.5379494007989347,
            0.5457463884430177,
            0.5349794238683129,
            0.554945054945055,
            0.559322033898305,
            0.5718309859154929,
            0.5530085959885387,
            0.5509325681492109,
            0.5491923641703378,
            0.5744047619047619,
            0.5722983257229832,
            0.5514018691588786,
            0.561622464898596,
            0.5535465924895688,
            0.5539358600583091,
            0.5459533607681756,
            0.5545977011494253,
            0.5365853658536585,
            0.5985401459854013,
            0.5681492109038738,
            0.5539358600583091,
            0.5705705705705705,
            0.5722543352601156,
            0.5417236662106704
        ],
        "best_epoch": 94,
        "best_epoch_f1": 0.5985401459854013,
        "training_time": 3099.109367132187,
        "test_set": {
            "f1": 0.5730659025787966,
            "precision": 0.5928853754940712,
            "recall": 0.5545286506469501
        }
    }
}