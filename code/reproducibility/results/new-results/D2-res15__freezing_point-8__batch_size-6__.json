{
    "setup": {
        "filename": "D2-res15__freezing_point-8__batch_size-6__.json",
        "dataset": "D2-res15",
        "device": "NVIDIA GeForce RTX 3050 Laptop GPU",
        "model_param": {
            "tag": "bert unfreeze layers",
            "freezing_point": 8,
            "prefix": "../data/D2/",
            "model_dir": "savemodel/",
            "task": "triplet",
            "mode": "train",
            "dataset": "res15",
            "max_sequence_len": 102,
            "device": "cuda",
            "bert_model_path": "bert-base-uncased",
            "bert_feature_dim": 768,
            "batch_size": 6,
            "epochs": 100,
            "class_num": 10,
            "seed": 1000,
            "learning_rate": 0.001,
            "bert_lr": 2e-05,
            "adam_epsilon": 1e-08,
            "weight_decay": 0.0,
            "emb_dropout": 0.5,
            "num_layers": 1,
            "pooling": "avg",
            "gcn_dim": 300,
            "relation_constraint": true,
            "symmetry_decoding": false,
            "post_size": 70,
            "deprel_size": 45,
            "postag_size": 826,
            "synpost_size": 7
        }
    },
    "results": {
        "dev_set": [
            0.3592017738359202,
            0.31763122476446837,
            0.38304552590266877,
            0.45606694560669453,
            0.4938875305623472,
            0.5599999999999999,
            0.5594989561586639,
            0.5493562231759657,
            0.540952380952381,
            0.5226917057902973,
            0.5603448275862069,
            0.5816326530612245,
            0.4943820224719102,
            0.5427135678391959,
            0.5963636363636364,
            0.5674255691768826,
            0.5882352941176471,
            0.5725047080979285,
            0.5968028419182949,
            0.5431654676258992,
            0.575591985428051,
            0.5798611111111112,
            0.5954465849387041,
            0.5767918088737201,
            0.6361829025844931,
            0.6369426751592356,
            0.6153846153846154,
            0.5475409836065573,
            0.6225165562913907,
            0.5622489959839357,
            0.6121593291404612,
            0.5815602836879432,
            0.618320610687023,
            0.6240601503759398,
            0.6095238095238096,
            0.6021897810218977,
            0.6080000000000001,
            0.6125760649087222,
            0.614406779661017,
            0.5807622504537205,
            0.6237816764132554,
            0.609625668449198,
            0.6116322701688556,
            0.5888324873096447,
            0.6026871401151632,
            0.6352941176470588,
            0.6151142355008787,
            0.6282527881040892,
            0.6035502958579881,
            0.6285714285714286,
            0.5919439579684763,
            0.6046511627906976,
            0.6240875912408759,
            0.631578947368421,
            0.6390977443609023,
            0.6003430531732418,
            0.6247544204322201,
            0.6079136690647482,
            0.6058394160583941,
            0.61010101010101,
            0.6029411764705883,
            0.6136783733826248,
            0.5968028419182949,
            0.6264150943396226,
            0.619047619047619,
            0.607773851590106,
            0.6039783001808319,
            0.6133828996282529,
            0.6027397260273972,
            0.6447876447876448,
            0.6269230769230769,
            0.6027397260273972,
            0.6254980079681276,
            0.6138613861386139,
            0.6293436293436293,
            0.6303939962476547,
            0.6281310211946051,
            0.6369168356997972,
            0.6051660516605165,
            0.6524271844660193,
            0.5714285714285715,
            0.6083916083916084,
            0.6167883211678833,
            0.609009009009009,
            0.6238532110091743,
            0.6324435318275154,
            0.6118067978533095,
            0.6132404181184669,
            0.6384615384615385,
            0.6285714285714286,
            0.6285714285714286,
            0.6198198198198199,
            0.6410748560460653,
            0.5826235093696764,
            0.5970695970695971,
            0.6250000000000001,
            0.6045694200351494,
            0.5782312925170069,
            0.6129032258064516,
            0.63003663003663
        ],
        "best_epoch": 79,
        "best_epoch_f1": 0.6524271844660193,
        "training_time": 2299.3252432346344,
        "test_set": {
            "f1": 0.5776850886339937,
            "precision": 0.5843881856540084,
            "recall": 0.5711340206185567
        }
    }
}